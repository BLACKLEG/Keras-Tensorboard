{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorboard in c:\\users\\bilel\\anaconda3\\lib\\site-packages (2.3.0)Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: protobuf>=3.6.0 in c:\\users\\bilel\\anaconda3\\lib\\site-packages (from tensorboard) (3.13.0)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in c:\\users\\bilel\\anaconda3\\lib\\site-packages (from tensorboard) (1.33.2)\n",
      "Requirement already satisfied: six>=1.10.0 in c:\\users\\bilel\\anaconda3\\lib\\site-packages (from tensorboard) (1.15.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\bilel\\anaconda3\\lib\\site-packages (from tensorboard) (1.7.0)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in c:\\users\\bilel\\anaconda3\\lib\\site-packages (from tensorboard) (0.34.2)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in c:\\users\\bilel\\anaconda3\\lib\\site-packages (from tensorboard) (1.23.0)\n",
      "\n",
      "Requirement already satisfied: absl-py>=0.4 in c:\\users\\bilel\\anaconda3\\lib\\site-packages (from tensorboard) (0.11.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\bilel\\anaconda3\\lib\\site-packages (from tensorboard) (3.3.3)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\bilel\\anaconda3\\lib\\site-packages (from tensorboard) (1.0.1)\n",
      "Requirement already satisfied: numpy>=1.12.0 in c:\\users\\bilel\\anaconda3\\lib\\site-packages (from tensorboard) (1.18.5)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\bilel\\anaconda3\\lib\\site-packages (from tensorboard) (49.2.0.post20200714)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\bilel\\anaconda3\\lib\\site-packages (from tensorboard) (0.4.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\bilel\\anaconda3\\lib\\site-packages (from tensorboard) (2.24.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\bilel\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.5\" in c:\\users\\bilel\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard) (4.6)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\bilel\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard) (4.1.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\bilel\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (1.3.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\bilel\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\bilel\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard) (1.25.9)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\bilel\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\bilel\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard) (2020.6.20)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\bilel\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\bilel\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (3.1.0)\n"
     ]
    }
   ],
   "source": [
    "pip install tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/moncoachdata/DATA_DEEP_LEARNING/master/cancer_classification.csv'\n",
    "df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>benign_0__mal_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>...</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>...</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>...</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>...</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>...</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0          17.99         10.38          122.80     1001.0          0.11840   \n",
       "1          20.57         17.77          132.90     1326.0          0.08474   \n",
       "2          19.69         21.25          130.00     1203.0          0.10960   \n",
       "3          11.42         20.38           77.58      386.1          0.14250   \n",
       "4          20.29         14.34          135.10     1297.0          0.10030   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "564        21.56         22.39          142.00     1479.0          0.11100   \n",
       "565        20.13         28.25          131.20     1261.0          0.09780   \n",
       "566        16.60         28.08          108.30      858.1          0.08455   \n",
       "567        20.60         29.33          140.10     1265.0          0.11780   \n",
       "568         7.76         24.54           47.92      181.0          0.05263   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0             0.27760         0.30010              0.14710         0.2419   \n",
       "1             0.07864         0.08690              0.07017         0.1812   \n",
       "2             0.15990         0.19740              0.12790         0.2069   \n",
       "3             0.28390         0.24140              0.10520         0.2597   \n",
       "4             0.13280         0.19800              0.10430         0.1809   \n",
       "..                ...             ...                  ...            ...   \n",
       "564           0.11590         0.24390              0.13890         0.1726   \n",
       "565           0.10340         0.14400              0.09791         0.1752   \n",
       "566           0.10230         0.09251              0.05302         0.1590   \n",
       "567           0.27700         0.35140              0.15200         0.2397   \n",
       "568           0.04362         0.00000              0.00000         0.1587   \n",
       "\n",
       "     mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                   0.07871  ...          17.33           184.60      2019.0   \n",
       "1                   0.05667  ...          23.41           158.80      1956.0   \n",
       "2                   0.05999  ...          25.53           152.50      1709.0   \n",
       "3                   0.09744  ...          26.50            98.87       567.7   \n",
       "4                   0.05883  ...          16.67           152.20      1575.0   \n",
       "..                      ...  ...            ...              ...         ...   \n",
       "564                 0.05623  ...          26.40           166.10      2027.0   \n",
       "565                 0.05533  ...          38.25           155.00      1731.0   \n",
       "566                 0.05648  ...          34.12           126.70      1124.0   \n",
       "567                 0.07016  ...          39.42           184.60      1821.0   \n",
       "568                 0.05884  ...          30.37            59.16       268.6   \n",
       "\n",
       "     worst smoothness  worst compactness  worst concavity  \\\n",
       "0             0.16220            0.66560           0.7119   \n",
       "1             0.12380            0.18660           0.2416   \n",
       "2             0.14440            0.42450           0.4504   \n",
       "3             0.20980            0.86630           0.6869   \n",
       "4             0.13740            0.20500           0.4000   \n",
       "..                ...                ...              ...   \n",
       "564           0.14100            0.21130           0.4107   \n",
       "565           0.11660            0.19220           0.3215   \n",
       "566           0.11390            0.30940           0.3403   \n",
       "567           0.16500            0.86810           0.9387   \n",
       "568           0.08996            0.06444           0.0000   \n",
       "\n",
       "     worst concave points  worst symmetry  worst fractal dimension  \\\n",
       "0                  0.2654          0.4601                  0.11890   \n",
       "1                  0.1860          0.2750                  0.08902   \n",
       "2                  0.2430          0.3613                  0.08758   \n",
       "3                  0.2575          0.6638                  0.17300   \n",
       "4                  0.1625          0.2364                  0.07678   \n",
       "..                    ...             ...                      ...   \n",
       "564                0.2216          0.2060                  0.07115   \n",
       "565                0.1628          0.2572                  0.06637   \n",
       "566                0.1418          0.2218                  0.07820   \n",
       "567                0.2650          0.4087                  0.12400   \n",
       "568                0.0000          0.2871                  0.07039   \n",
       "\n",
       "     benign_0__mal_1  \n",
       "0                  0  \n",
       "1                  0  \n",
       "2                  0  \n",
       "3                  0  \n",
       "4                  0  \n",
       "..               ...  \n",
       "564                0  \n",
       "565                0  \n",
       "566                0  \n",
       "567                0  \n",
       "568                1  \n",
       "\n",
       "[569 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x et y \n",
    "X = df.iloc [ : , :-1 ] .values \n",
    "y = df.iloc [ : , -1 ] .values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set de train et test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalise \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler ()\n",
    "X_train = scaler.fit_transform ( X_train )\n",
    "X_test = scaler.transform ( X_test )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(455, 30)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import  TensorBoard\n",
    "%load_ext tensorboard    #charger l extension\n",
    "\n",
    "# creation du dossier de logs \n",
    "log_directory = 'logs\\\\fit'\n",
    "\n",
    "#appel tensorboard\n",
    "board_callback = TensorBoard(log_dir=log_directory , \n",
    "                                   histogram_freq=1 ,\n",
    "                                   write_graph = True ,\n",
    "                                   write_images = True ,\n",
    "                                   update_freq = 'epoch' ,\n",
    "                                   profile_batch = 2 , \n",
    "                                   embeddings_freq =1   )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.7205WARNING:tensorflow:From C:\\Users\\bilel\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      " 2/15 [===>..........................] - ETA: 1s - loss: 0.7089WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0040s vs `on_train_batch_end` time: 0.1767s). Check your callbacks.\n",
      "15/15 [==============================] - 1s 85ms/step - loss: 0.6929 - val_loss: 0.6717\n",
      "Epoch 2/300\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.6861 - val_loss: 0.6635\n",
      "Epoch 3/300\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.6648 - val_loss: 0.6506\n",
      "Epoch 4/300\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6694 - val_loss: 0.6307\n",
      "Epoch 5/300\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6550 - val_loss: 0.6191\n",
      "Epoch 6/300\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6402 - val_loss: 0.5989\n",
      "Epoch 7/300\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.6157 - val_loss: 0.5685\n",
      "Epoch 8/300\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.5802 - val_loss: 0.5414\n",
      "Epoch 9/300\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.5686 - val_loss: 0.5013\n",
      "Epoch 10/300\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.5656 - val_loss: 0.4577\n",
      "Epoch 11/300\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.5151 - val_loss: 0.4258\n",
      "Epoch 12/300\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.5321 - val_loss: 0.4058\n",
      "Epoch 13/300\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.5159 - val_loss: 0.3825\n",
      "Epoch 14/300\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.4654 - val_loss: 0.3536\n",
      "Epoch 15/300\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.4601 - val_loss: 0.3428\n",
      "Epoch 16/300\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.4668 - val_loss: 0.3122\n",
      "Epoch 17/300\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.4238 - val_loss: 0.3001\n",
      "Epoch 18/300\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.4242 - val_loss: 0.2797\n",
      "Epoch 19/300\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.3912 - val_loss: 0.2621\n",
      "Epoch 20/300\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.3930 - val_loss: 0.2459\n",
      "Epoch 21/300\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.3476 - val_loss: 0.2280\n",
      "Epoch 22/300\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.3704 - val_loss: 0.2122\n",
      "Epoch 23/300\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.3774 - val_loss: 0.2052\n",
      "Epoch 24/300\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.3399 - val_loss: 0.1987\n",
      "Epoch 25/300\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.3316 - val_loss: 0.2011\n",
      "Epoch 26/300\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.3514 - val_loss: 0.1837\n",
      "Epoch 27/300\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.3488 - val_loss: 0.1838\n",
      "Epoch 28/300\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.3085 - val_loss: 0.1770\n",
      "Epoch 29/300\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.3016 - val_loss: 0.1630\n",
      "Epoch 30/300\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.3177 - val_loss: 0.1542\n",
      "Epoch 31/300\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.2717 - val_loss: 0.1434\n",
      "Epoch 32/300\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.3122 - val_loss: 0.1458\n",
      "Epoch 33/300\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.3050 - val_loss: 0.1404\n",
      "Epoch 34/300\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.2711 - val_loss: 0.1315\n",
      "Epoch 35/300\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.2620 - val_loss: 0.1314\n",
      "Epoch 36/300\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.2602 - val_loss: 0.1265\n",
      "Epoch 37/300\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.2573 - val_loss: 0.1212\n",
      "Epoch 38/300\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.2619 - val_loss: 0.1173\n",
      "Epoch 39/300\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.2707 - val_loss: 0.1226\n",
      "Epoch 40/300\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.2373 - val_loss: 0.1166\n",
      "Epoch 41/300\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.2475 - val_loss: 0.1093\n",
      "Epoch 42/300\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.2386 - val_loss: 0.1057\n",
      "Epoch 43/300\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.2572 - val_loss: 0.1050\n",
      "Epoch 44/300\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.2172 - val_loss: 0.1045\n",
      "Epoch 45/300\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.2179 - val_loss: 0.0993\n",
      "Epoch 46/300\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.1826 - val_loss: 0.0990\n",
      "Epoch 47/300\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.2068 - val_loss: 0.1009\n",
      "Epoch 48/300\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.2065 - val_loss: 0.0936\n",
      "Epoch 49/300\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.2148 - val_loss: 0.0901\n",
      "Epoch 50/300\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.2107 - val_loss: 0.0938\n",
      "Epoch 51/300\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.1777 - val_loss: 0.0851\n",
      "Epoch 52/300\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.1789 - val_loss: 0.0864\n",
      "Epoch 53/300\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.2059 - val_loss: 0.0851\n",
      "Epoch 54/300\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.1799 - val_loss: 0.0840\n",
      "Epoch 55/300\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1980 - val_loss: 0.0823\n",
      "Epoch 56/300\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1691 - val_loss: 0.0828\n",
      "Epoch 57/300\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1555 - val_loss: 0.0813\n",
      "Epoch 58/300\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.1588 - val_loss: 0.0751\n",
      "Epoch 59/300\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.1348 - val_loss: 0.0743\n",
      "Epoch 60/300\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.1549 - val_loss: 0.0724\n",
      "Epoch 61/300\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.1494 - val_loss: 0.0732\n",
      "Epoch 62/300\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.1468 - val_loss: 0.0739\n",
      "Epoch 63/300\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.1282 - val_loss: 0.0701\n",
      "Epoch 64/300\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.1382 - val_loss: 0.0724\n",
      "Epoch 65/300\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.1457 - val_loss: 0.0704\n",
      "Epoch 66/300\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.1175 - val_loss: 0.0712\n",
      "Epoch 67/300\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.1529 - val_loss: 0.0638\n",
      "Epoch 68/300\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.1116 - val_loss: 0.0657\n",
      "Epoch 69/300\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.1472 - val_loss: 0.0600\n",
      "Epoch 70/300\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.1416 - val_loss: 0.0735\n",
      "Epoch 71/300\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1278 - val_loss: 0.0586\n",
      "Epoch 72/300\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.1592 - val_loss: 0.0708\n",
      "Epoch 73/300\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.1276 - val_loss: 0.0547\n",
      "Epoch 74/300\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.1206 - val_loss: 0.0611\n",
      "Epoch 75/300\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.1494 - val_loss: 0.0668\n",
      "Epoch 76/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 9ms/step - loss: 0.1027 - val_loss: 0.0701\n",
      "Epoch 77/300\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.1183 - val_loss: 0.0564\n",
      "Epoch 78/300\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1320 - val_loss: 0.0576\n",
      "Epoch 79/300\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1201 - val_loss: 0.0575\n",
      "Epoch 80/300\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1460 - val_loss: 0.0663\n",
      "Epoch 81/300\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1260 - val_loss: 0.0546\n",
      "Epoch 82/300\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.1089 - val_loss: 0.0635\n",
      "Epoch 83/300\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.1402 - val_loss: 0.0537\n",
      "Epoch 84/300\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.1133 - val_loss: 0.0674\n",
      "Epoch 85/300\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1202 - val_loss: 0.0589\n",
      "Epoch 86/300\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.1148 - val_loss: 0.0633\n",
      "Epoch 87/300\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.1175 - val_loss: 0.0625\n",
      "Epoch 88/300\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.1291 - val_loss: 0.0573\n",
      "Epoch 89/300\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.1128 - val_loss: 0.0564\n",
      "Epoch 90/300\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.1038 - val_loss: 0.0605\n",
      "Epoch 91/300\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.1002 - val_loss: 0.0648\n",
      "Epoch 92/300\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.1120 - val_loss: 0.0638\n",
      "Epoch 93/300\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.1082 - val_loss: 0.0589\n",
      "Epoch 94/300\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0958 - val_loss: 0.0555\n",
      "Epoch 95/300\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.1024 - val_loss: 0.0563\n",
      "Epoch 96/300\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.1016 - val_loss: 0.0622\n",
      "Epoch 97/300\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.1083 - val_loss: 0.0564\n",
      "Epoch 98/300\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0980 - val_loss: 0.0573\n",
      "Epoch 00098: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e181607700>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reseau de neurone\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense , Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n",
    "\n",
    "model = Sequential ()\n",
    "model.add( Dense ( 30 , activation = 'relu')  )\n",
    "model.add( Dropout (0.3)  )\n",
    "model.add( Dense ( 20 , activation = 'relu')  )\n",
    "model.add( Dropout ( 0.5 ))\n",
    "model.add( Dense ( 10 , activation = 'relu')  )\n",
    "model.add(Dropout   (0.5 ))\n",
    "model.add( Dense ( 5 , activation = 'relu')  )\n",
    "model.add( Dense ( 1 , activation = 'sigmoid')  )\n",
    "\n",
    "model.compile ( optimizer='Adam',\n",
    "                loss= 'binary_crossentropy')\n",
    "\n",
    "ea_stop = EarlyStopping ( monitor='val_loss',\n",
    "                          mode = 'min' ,   #minimisé la val loss\n",
    "                          verbose = 1 ,   # rapport\n",
    "                          patience=15 )\n",
    "\n",
    "model.fit ( x=X_train,\n",
    "    y=y_train,\n",
    "    epochs=300,\n",
    "    callbacks = [ea_stop , board_callback] ,\n",
    "    validation_data=(X_test,y_test),)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# courbe d apprentissage \n",
    "pd.DataFrame (model.history.history ).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98        43\n",
      "           1       0.99      0.99      0.99        71\n",
      "\n",
      "    accuracy                           0.98       114\n",
      "   macro avg       0.98      0.98      0.98       114\n",
      "weighted avg       0.98      0.98      0.98       114\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0   0   1\n",
       "row_0        \n",
       "0      42   1\n",
       "1       1  70"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# metrics d erreurs \n",
    "\n",
    "from sklearn.metrics import classification_report \n",
    "pred = model.predict (X_test).reshape (114,)\n",
    "pred = (pred>0.5).astype ('int')\n",
    "print (classification_report ( pred , y_test ))\n",
    "\n",
    "pd.crosstab(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logs\\fit\n"
     ]
    }
   ],
   "source": [
    "print (log_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 5540), started 0:01:53 ago. (Use '!kill 5540' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-dc0ae808a6fcdba4\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-dc0ae808a6fcdba4\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# manceùent de tensor board \n",
    "%tensorboard --logdir logs/fit"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
